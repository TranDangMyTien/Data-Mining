# -*- coding: utf-8 -*-
"""BTH07_KPDL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w_RnZyB_QULfMrmU8gDBGvAOmujx0-fL
"""

from google.colab import drive
drive.mount('/content/drive')

"""## Câu 1"""

import pandas as pd

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/KPDL/CAC BUOI THUC HANH/BTH07/bank-data.csv")

df.info()
df.head()

# Tính toán các giá trị thống kê mô tả cho cột tuổi và thu nhập:
print(df['age'].describe().round(2))
print(df['income'].describe().round(2))

# Vẽ 2 biểu đồ phân bố tần số của tuổi và thu nhập:
import matplotlib.pyplot as plt

plt.hist(df['age'], bins=20)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Age Distribution')

plt.figure()

plt.hist(df['income'], bins=20)
plt.xlabel('Income')
plt.ylabel('Frequency')
plt.title('Income Distribution')

plt.show()

# Xóa cột id để ẩn danh thông tin cá nhân
df.drop("id", axis=1, inplace=True)
df

# Tính mode của các cột tình trạng hôn nhân và số con:
print(df['married'].mode())
print(df['children'].mode())

# Lưu dữ liệu vào tập tin mới Bank-Data-Clustering.csv:
df.to_csv('/content/drive/MyDrive/Colab Notebooks/KPDL/CAC BUOI THUC HANH/BTH07/Bank-Data-Clustering.csv', index=False)

"""## Câu 2"""

# Đọc dữ liệu từ Bank-Data-Clustering.csv
import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/KPDL/CAC BUOI THUC HANH/BTH07/Bank-Data-Clustering.csv')
df

from sklearn.preprocessing import LabelEncoder

# Các cột categorical cần convert thành dạng số
le = LabelEncoder()
df['sex'] = le.fit_transform(df['sex'])
df['region'] = le.fit_transform(df['region'])
df['married'] = le.fit_transform(df['married'])
df['car'] = le.fit_transform(df['car'])
df['save_act'] = le.fit_transform(df['save_act'])
df['current_act'] = le.fit_transform(df['current_act'])
df['mortgage'] = le.fit_transform(df['mortgage'])
# ** Cột 'pep' là target nên không cần chuẩn hóa.
df.to_csv('/content/drive/MyDrive/Colab Notebooks/KPDL/CAC BUOI THUC HANH/BTH07/Bank-Data-Clustering_std.csv', index=False)
df

# Tách thành 2 tập tin Train và Test, trong đó Test chứa 50 dòng cuối
df_train = df.iloc[:-50]
df_test = df.iloc[-50:]

df_train.to_csv('/content/drive/MyDrive/Colab Notebooks/KPDL/CAC BUOI THUC HANH/BTH07/Bank-Data-Clustering-Train.csv', index=False)
df_test.to_csv('/content/drive/MyDrive/Colab Notebooks/KPDL/CAC BUOI THUC HANH/BTH07/Bank-Data-Clustering-Test.csv', index=False)

from sklearn.cluster import KMeans

# Loại bỏ cột 'pep' từ cả 2 tập dữ liệu Train và Test
X_train = df_train.drop('pep', axis=1)

# Thực hiện gom cụm KMean cho tập Train với k=2, k=3, k=4
kmeans2 = KMeans(n_clusters=2, random_state=0).fit(X_train)
kmeans3 = KMeans(n_clusters=3, random_state=0).fit(X_train)
kmeans4 = KMeans(n_clusters=4, random_state=0).fit(X_train)

# Fit model KMeans với dữ liệu đã được chuẩn hóa:
X_train = df_train.drop('pep', axis=1)

y_pred_2 = kmeans2.predict(X_train) #k=2
y_pred_3 = kmeans3.predict(X_train) #k=3
y_pred_4 = kmeans4.predict(X_train) #k=4

import matplotlib.pyplot as plt

plt.xlabel('Age')
plt.ylabel('Income')

plt.scatter(X_train['age'], X_train['income'], c=y_pred_2)
plt.show()

plt.scatter(X_train['age'], X_train['income'], c=y_pred_3)
plt.show()

plt.scatter(X_train['age'], X_train['income'], c=y_pred_4)
plt.show()

"""Để đánh giá chất lượng mô hình phân cụm, ta có thể sử dụng các thông số:

* Confusion matrix: Ma trận nhầm lẫn so sánh nhãn thực tế và nhãn dự đoán

* True positives (TP): Số mẫu dự đoán đúng thuộc lớp positive

* False positives (FP): Số mẫu dự đoán nhầm thuộc lớp positive

* Recall: Tỷ lệ TP trên tổng số mẫu thực tế thuộc lớp positive
"""

from sklearn.metrics import confusion_matrix, classification_report

le = LabelEncoder()
df_train['pep'] = le.fit_transform(df_train['pep'])
y_true = df_train['pep']

print(confusion_matrix(y_true, y_pred_2))
print(classification_report(y_true, y_pred_2))

# Fit model KMeans với dữ liệu đã được chuẩn hóa:
X_test = df_test.drop('pep', axis=1)

y_pred_2 = kmeans2.predict(X_test) #k=2
y_pred_3 = kmeans3.predict(X_test) #k=3
y_pred_4 = kmeans4.predict(X_test) #k=4

import matplotlib.pyplot as plt

plt.xlabel('Age')
plt.ylabel('Income')

plt.scatter(X_test['age'], X_test['income'], c=y_pred_2)
plt.show()

plt.scatter(X_test['age'], X_test['income'], c=y_pred_3)
plt.show()

plt.scatter(X_test['age'], X_test['income'], c=y_pred_4)
plt.show()

from sklearn.metrics import confusion_matrix, classification_report

le = LabelEncoder()
df_test['pep'] = le.fit_transform(df_test['pep'])
y_true = df_test['pep']

print(confusion_matrix(y_true, y_pred_2))
print(classification_report(y_true, y_pred_2))

"""## Câu 3"""

import pandas as pd
# Chia tập dữ liệu thành tập train (80%) và tập test (20%):
from sklearn.model_selection import train_test_split

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/KPDL/CAC BUOI THUC HANH/BTH07/Bank-Data-Clustering_std.csv")

X = df.drop('pep', axis=1)
y = df['pep']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Xây dựng mô hình KNN với K lần lượt là 3, 5, 7, 9 trên tập train:
from sklearn.neighbors import KNeighborsClassifier

knn_3 = KNeighborsClassifier(n_neighbors=3)
knn_5 = KNeighborsClassifier(n_neighbors=5)
knn_7 = KNeighborsClassifier(n_neighbors=7)
knn_9 = KNeighborsClassifier(n_neighbors=9)
knn_11 = KNeighborsClassifier(n_neighbors=11)

knn_3.fit(X_train, y_train)
knn_5.fit(X_train, y_train)
knn_7.fit(X_train, y_train)
knn_9.fit(X_train, y_train)
knn_11.fit(X_train, y_train)

# Đánh giá mô hình trên tập test:
y_pred_3 = knn_3.predict(X_test)
y_pred_5 = knn_5.predict(X_test)
y_pred_7 = knn_7.predict(X_test)
y_pred_9 = knn_9.predict(X_test)
y_pred_11 = knn_11.predict(X_test)

# Tính toán sai số trên tập train và test:
from sklearn.metrics import accuracy_score

train_error_3 = 1 - accuracy_score(y_train, knn_3.predict(X_train))
test_error_3 = 1 - accuracy_score(y_test, y_pred_3)

train_error_5 = 1 - accuracy_score(y_train, knn_5.predict(X_train))
test_error_5 = 1 - accuracy_score(y_test, y_pred_5)

train_error_7 = 1 - accuracy_score(y_train, knn_7.predict(X_train))
test_error_7 = 1 - accuracy_score(y_test, y_pred_7)

train_error_9 = 1 - accuracy_score(y_train, knn_9.predict(X_train))
test_error_9 = 1 - accuracy_score(y_test, y_pred_9)

train_error_11 = 1 - accuracy_score(y_train, knn_11.predict(X_train))
test_error_11 = 1 - accuracy_score(y_test, y_pred_11)

# Vẽ đồ thị sai số:
import matplotlib.pyplot as plt

plt.plot([3,5,7,9,11], [train_error_3, train_error_5, train_error_7, train_error_9, train_error_11], label='Train error')
plt.plot([3,5,7,9,11], [test_error_3, test_error_5, test_error_7, test_error_9, test_error_11], label='Test error')

plt.xlabel('K')
plt.ylabel('Error')
plt.legend()

plt.show()

# Xuất thành dạng bảng:
K_values = [3, 5, 7, 9, 11]
train_errors = [train_error_3, train_error_5, train_error_7, train_error_9, train_error_11]
test_errors = [test_error_3, test_error_5, test_error_7, test_error_9, test_error_11]

# Tạo dataframe từ các list trên
df_demo = pd.DataFrame({'K': K_values,
                  'Train Error': train_errors,
                  'Test Error': test_errors})

# Xuất dataframe ra file .csv
df_demo

# Xét điểm dữ liệu có Test_error thấp nhất làm K-Best -> xét thêm K=11 để đảm bảo không có giảm thêm!
# => K best = 9

"""## Câu 4"""

from sklearn.preprocessing import LabelEncoder
# Chia tập dữ liệu thành tập train (80%) và tập test (20%):
from sklearn.model_selection import train_test_split

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/KPDL/CAC BUOI THUC HANH/BTH07/Bank-Data-Clustering_std.csv")

le = LabelEncoder()
df['pep'] = le.fit_transform(df['pep']) # Chuẩn hóa cột pep từ YES NO -> 0 1

X = df.drop('pep', axis=1)
y = df['pep']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Xây dựng các mô hình Decision Tree, REP Tree và Random Forest trên tập train với chiều cao cây lần lượt là 4, 5, 6:
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import ExtraTreeClassifier
from sklearn.ensemble import RandomForestClassifier

dt_4 = DecisionTreeClassifier(max_depth=4)
dt_5 = DecisionTreeClassifier(max_depth=5)
dt_6 = DecisionTreeClassifier(max_depth=6)

rep_4 = ExtraTreeClassifier(max_depth=4)
rep_5 = ExtraTreeClassifier(max_depth=5)
rep_6 = ExtraTreeClassifier(max_depth=6)

rf_4 = RandomForestClassifier(max_depth=4)
rf_5 = RandomForestClassifier(max_depth=5)
rf_6 = RandomForestClassifier(max_depth=6)

dt_4.fit(X_train, y_train)
dt_5.fit(X_train, y_train)
dt_6.fit(X_train, y_train)

rep_4.fit(X_train, y_train)
rep_5.fit(X_train, y_train)
rep_6.fit(X_train, y_train)

rf_4.fit(X_train, y_train)
rf_5.fit(X_train, y_train)
rf_6.fit(X_train, y_train)

# Đánh giá các mô hình trên tập test:
y_pred_dt4 = dt_4.predict(X_test)
y_pred_dt5 = dt_5.predict(X_test)
y_pred_dt6 = dt_6.predict(X_test)

y_pred_rep4 = rep_4.predict(X_test)
y_pred_rep5 = rep_5.predict(X_test)
y_pred_rep6 = rep_6.predict(X_test)

y_pred_rf4 = rf_4.predict(X_test)
y_pred_rf5 = rf_5.predict(X_test)
y_pred_rf6 = rf_6.predict(X_test)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

algorithms = ["DT4", "DT5", "DT6", "REP4", "REP5", "REP6", "RF4", "RF5", "RF6"]
accuracies = []
precisions = []
recalls = []
f1_scores = []

for y_pred_ in [y_pred_dt4, y_pred_dt5, y_pred_dt6, y_pred_rep4, y_pred_rep5, y_pred_rep6, y_pred_rf4, y_pred_rf5, y_pred_rf6]:
    accuracies.append(accuracy_score(y_test, y_pred_))
    precisions.append(precision_score(y_test, y_pred_))
    recalls.append(recall_score(y_test, y_pred_))
    f1_scores.append(f1_score(y_test, y_pred_))

x = np.arange(len(algorithms))
width = 0.2

plt.bar(x - 0.2, accuracies, width, label='Accuracy', color='blue')
plt.bar(x, precisions, width, label='Precision', color='green')
plt.bar(x + 0.2, recalls, width, label='Recall', color='red')
plt.bar(x + 0.4, f1_scores, width, label='F1-score', color='yellow')

plt.xticks(x, algorithms)
plt.legend()
plt.title('Model Evaluation')
plt.show()
# Quan sát thấy Accuracy của DT6 cao nhất. REP 5 thấp nhất...

# Chọn 7 features quan trọng:
from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(f_classif, k=7)
selector.fit(X_train, y_train)

X_train_reduced = selector.transform(X_train)
X_test_reduced = selector.transform(X_test)

# Huấn luyện và đánh giá lại các mô hình trên tập dữ liệu đã giảm chiều:
dt_4.fit(X_train_reduced, y_train)
dt_5.fit(X_train_reduced, y_train)
dt_6.fit(X_train_reduced, y_train)

rep_4.fit(X_train_reduced, y_train)
rep_5.fit(X_train_reduced, y_train)
rep_6.fit(X_train_reduced, y_train)

rf_4.fit(X_train_reduced, y_train)
rf_5.fit(X_train_reduced, y_train)
rf_6.fit(X_train_reduced, y_train)

# Đánh giá lại các mô hình trên tập test:
y_pred_dt4 = dt_4.predict(X_test_reduced)
y_pred_dt5 = dt_5.predict(X_test_reduced)
y_pred_dt6 = dt_6.predict(X_test_reduced)

y_pred_rep4 = rep_4.predict(X_test_reduced)
y_pred_rep5 = rep_5.predict(X_test_reduced)
y_pred_rep6 = rep_6.predict(X_test_reduced)

y_pred_rf4 = rf_4.predict(X_test_reduced)
y_pred_rf5 = rf_5.predict(X_test_reduced)
y_pred_rf6 = rf_6.predict(X_test_reduced)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

algorithms = ["DT4", "DT5", "DT6", "REP4", "REP5", "REP6", "RF4", "RF5", "RF6"]
accuracies = []
precisions = []
recalls = []
f1_scores = []

for y_pred_ in [y_pred_dt4, y_pred_dt5, y_pred_dt6, y_pred_rep4, y_pred_rep5, y_pred_rep6, y_pred_rf4, y_pred_rf5, y_pred_rf6]:
    accuracies.append(accuracy_score(y_test, y_pred_))
    precisions.append(precision_score(y_test, y_pred_))
    recalls.append(recall_score(y_test, y_pred_))
    f1_scores.append(f1_score(y_test, y_pred_))

x = np.arange(len(algorithms))
width = 0.2

plt.bar(x - 0.2, accuracies, width, label='Accuracy', color='blue')
plt.bar(x, precisions, width, label='Precision', color='green')
plt.bar(x + 0.2, recalls, width, label='Recall', color='red')
plt.bar(x + 0.4, f1_scores, width, label='F1-score', color='yellow')

plt.xticks(x, algorithms)
plt.legend()
plt.title('Model Evaluation')
plt.show()